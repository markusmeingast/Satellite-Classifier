{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.5"},"colab":{"name":"segmentation.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"yOUqY1HexFdi","colab_type":"code","colab":{}},"source":["#!pip install tensorflow-gpu==2.0.0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5b0puRHLf491","colab_type":"code","colab":{}},"source":["################################################################################\n","# %% CONNECT TO DRIVE\n","################################################################################\n","\n","from google.colab import drive, files\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3btQkqxTf499","colab_type":"code","colab":{}},"source":["################################################################################\n","# %% IMPORT PACKAGES\n","################################################################################\n","\n","import os\n","import glob\n","import numpy as np\n","from tensorflow import keras\n","import tensorflow as tf\n","from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n","from sklearn.model_selection import train_test_split\n","import sys\n","from time import time\n","import matplotlib.pyplot as mp\n","from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, concatenate, UpSampling2D\n","from tensorflow.keras.optimizers import Adam\n","import pandas as pd\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator, random_brightness, random_zoom"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"spXkYpRff4-B","colab_type":"code","colab":{}},"source":["################################################################################\n","# %% LOAD DATA AND SPLIT INTO BATCHES\n","################################################################################\n","\n","def generate_data(dpath, batch_size=128, tag='train', aug=None):\n","\n","    ##### READ FOLDER CONTENTS\n","    fimg = sorted(glob.glob(dpath+f'image-{tag}*'))\n","    flbl = fimg\n","    flbl = [f.replace('image', 'label') for f in flbl] \n","\n","    ##### READ FIRST FILE TO BUFFER\n","    print(f'----> Reading {fimg[0]} <----')\n","    print(f'----> Reading {flbl[0]} <----')\n","    X_in = np.load(fimg[0])\n","    y_in = np.load(flbl[0])\n","\n","    ##### SHUFFLE\n","    idx = np.arange(len(X_in))\n","    idx = np.random.shuffle(idx)\n","\n","    X_in = X_in[idx][0, :, :, :, :]\n","    y_in = y_in[idx][0, :, :, :, :]\n","\n","    ##### START COUNTING\n","    i = 0\n","    \n","    ##### LOOP INDEFINITELY\n","    while True:\n","\n","        ##### IF BUFFER NOT SUFFICIENT TO COVER NEXT BATCH\n","        if len(X_in) < batch_size:\n","\n","            ##### SET NEXT INDEX BASED ON LENGHT OF FOLDER CONTENTS\n","            if i<len(fimg)-1:\n","                i += 1\n","            else:\n","                i = 0\n","            \n","            ##### APPEND NEXT FILE\n","            print(f'----> Reading {fimg[i]} <----')\n","            print(f'----> Reading {flbl[i]} <----')\n","            X_in = np.concatenate((X_in, np.load(fimg[i])), axis=0)\n","            y_in = np.concatenate((y_in, np.load(flbl[i])), axis=0)\n","\n","            ##### SHUFFLE\n","            idx = np.arange(len(X_in))\n","            idx = np.random.shuffle(idx)\n","\n","            X_in = X_in[idx][0, :, :, :, :]\n","            y_in = y_in[idx][0, :, :, :, :]\n","\n","        else:\n","            \n","            if aug:\n","                for idx in range(batch_size):\n","                    X_in[idx] = random_brightness(X_in[idx],(1.0-aug,1.0+aug))\n","                    #X_in[idx] = random_zoom(X_in[idx],(1.0,1.2), row_axis=0, col_axis=1, channel_axis=2)\n","\n","            ##### YIELD SET\n","            yield X_in[:batch_size, :, :, :], y_in[:batch_size, :, :, :]\n","\n","            ##### REMOVE YIELDED RESULTS\n","            X_in = np.delete(X_in, range(batch_size), axis=0)\n","            y_in = np.delete(y_in, range(batch_size), axis=0)\n","\n","##### INIT TRAINING DATA GENERATOR     \n","train_gen = generate_data('drive/My Drive/Data/', batch_size=512, tag='train', aug=0.5)\n","\n","##### INIT VALIDATION DATA GENERATOR\n","val_gen = generate_data('drive/My Drive/Data/', batch_size=512, tag='val', aug=0.5)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LoTQleI-f4-I","colab_type":"code","colab":{}},"source":["################################################################################\n","# %% UNET MODEL\n","################################################################################\n","\n","def unet_model(power=2):\n","  \n","  input_size = (256,256,3)\n","\n","  inputs = Input(input_size)\n","  conv1 = Conv2D(2**(power), 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_uniform')(inputs)\n","  conv1 = Conv2D(2**(power), 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_uniform')(conv1)\n","  pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n","  conv2 = Conv2D(2**(power+1), 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_uniform')(pool1)\n","  conv2 = Conv2D(2**(power+1), 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_uniform')(conv2)\n","  pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n","  conv3 = Conv2D(2**(power+2), 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_uniform')(pool2)\n","  conv3 = Conv2D(2**(power+2), 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_uniform')(conv3)\n","  pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n","  \n","  conv4 = Conv2D(2**(power+3), 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_uniform')(pool3)\n","  conv4 = Conv2D(2**(power+3), 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_uniform')(conv4)\n","  drop4 = Dropout(0.5)(conv4)\n","  pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n","\n","  conv5 = Conv2D(2**(power+4), 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_uniform')(pool4)\n","  conv5 = Conv2D(2**(power+4), 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_uniform')(conv5)\n","  drop5 = Dropout(0.5)(conv5)\n","\n","  up6 = Conv2D(2**(power+3), 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_uniform')(UpSampling2D(size = (2,2), interpolation='bilinear')(drop5))\n","  merge6 = concatenate([drop4,up6], axis = 3)\n","  conv6 = Conv2D(2**(power+3), 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_uniform')(merge6)\n","  conv6 = Conv2D(2**(power+3), 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_uniform')(conv6)\n","\n","  up7 = Conv2D(2**(power+2), 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_uniform')(UpSampling2D(size = (2,2), interpolation='bilinear')(conv6))\n","  merge7 = concatenate([conv3,up7], axis = 3)\n","  conv7 = Conv2D(2**(power+2), 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_uniform')(merge7)\n","  conv7 = Conv2D(2**(power+2), 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_uniform')(conv7)\n","\n","  up8 = Conv2D(2**(power+1), 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_uniform')(UpSampling2D(size = (2,2), interpolation='bilinear')(conv7))\n","  merge8 = concatenate([conv2,up8], axis = 3)\n","  conv8 = Conv2D(2**(power+1), 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_uniform')(merge8)\n","  conv8 = Conv2D(2**(power+1), 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_uniform')(conv8)\n","\n","  up9 = Conv2D(2**(power), 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_uniform')(UpSampling2D(size = (2,2), interpolation='bilinear')(conv8))\n","  merge9 = concatenate([conv1,up9], axis = 3)\n","  conv9 = Conv2D(2**(power), 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_uniform')(merge9)\n","  conv9 = Conv2D(2**(power), 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_uniform')(conv9)\n","  conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_uniform')(conv9)\n","  conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n","\n","  model = keras.Model(inputs = inputs, outputs = conv10)\n","  return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8u8oJoPVykub","colab_type":"code","colab":{}},"source":["################################################################################\n","# %% BUILD UNET MODEL\n","################################################################################\n","\n","model = unet_model(4)\n","model.compile(optimizer = Adam(), loss = 'binary_crossentropy', metrics = ['accuracy'])\n","model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TtZ1cDNiy5fc","colab_type":"code","colab":{}},"source":["################################################################################\n","# %% INIT CALLBACKS\n","################################################################################\n","\n","#tensorboard = TensorBoard(log_dir='logs/{}'.format(time()), update_freq='epoch')\n","#earlystopping = EarlyStopping(monitor='loss', patience=100)\n","modelcheckpoint = ModelCheckpoint('drive/My Drive/Data/keras_model_checkpoint.h5', monitor='loss',verbose=1, save_best_only=True)#, save_freq='epoch')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vGj-rhr2y7G1","colab_type":"code","colab":{}},"source":["%%time\n","\n","################################################################################\n","# %% RUN MODEL\n","################################################################################\n","\n","##### RESTART\n","#model = tf.keras.models.load_model('drive/My Drive/Data/keras_model_checkpoint.h5')\n","#model.load_weights(\"drive/My Drive/Data/keras_model.h5\")\n","\n","##### INIT HISTORY IF NOT RESTARTING\n","if 'loss' not in locals():\n","    loss = []\n","    acc = []\n","    val_loss = []\n","    val_acc = []\n","\n","##### TRAIN\n","for iter in range(8):\n","    print(f'Outer iteration {iter}')\n","\n","    ##### GEN NEXT DATA SETS FROM GENERATORS AND NORMALIZE\n","    X_train, y_train = next(train_gen)\n","    X_test, y_test = next(val_gen)\n","    X_train = X_train/255.0\n","    X_test = X_test/255.0\n","\n","    ##### FIT MODEL ON CURRENT DATASET\n","    history = model.fit( \n","        x = X_train,\n","        y = y_train,\n","        validation_data=(X_test, y_test),\n","        epochs=10,\n","        verbose=1,\n","        use_multiprocessing=True,\n","        #batch_size=16,\n","        callbacks=[modelcheckpoint] #tensorboard earlystopping, \n","    )\n","\n","    ##### APPEND METRICS TO HISTORY\n","    loss.append(history.history['loss'])\n","    acc.append(history.history['acc'])\n","    val_loss.append(history.history['val_loss'])\n","    val_acc.append(history.history['val_acc'])\n","\n","##### SAVE UPON EXIT\n","model.save('drive/My Drive/Data/keras_model.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uyGor_P6hx00","colab_type":"code","colab":{}},"source":["################################################################################\n","# %% PLOTTING LOSS CURVE\n","################################################################################\n","\n","mp.semilogy(np.array(loss).flatten(), label='Training')\n","mp.semilogy(np.array(val_loss).flatten(), label='Testing')\n","mp.xlabel('Epochs')\n","mp.ylabel('Loss')\n","mp.legend()\n","mp.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KdQViDzOToSl","colab_type":"code","colab":{}},"source":["################################################################################\n","# %% PLOTTING ACCURACY CURVE\n","################################################################################\n","\n","mp.plot(np.array(acc).flatten(), label='Training')\n","mp.plot(np.array(val_acc).flatten(), label='Testing')\n","mp.xlabel('Epochs')\n","mp.ylabel('Accuracy')\n","mp.legend()\n","mp.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"frCph10ti7w1","colab_type":"code","colab":{}},"source":["################################################################################\n","# %% PLOTTING BASE TRUTH\n","################################################################################\n","\n","#X_test, y_test = next(val_gen)\n","#X_test = np.load('drive/My Drive/Data/image-train-3.npy')\n","#y_test = np.load('drive/My Drive/Data/label-train-3.npy')\n","\n","fig = mp.figure(figsize=(8,8))\n","\n","id = 103\n","\n","mp.imshow(X_test[id,:,:,:])\n","mp.imshow(y_test[id,:,:,0], alpha=0.5)\n","mp.axis('off')\n","mp.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ieeCriXAjAoo","colab_type":"code","colab":{}},"source":["################################################################################\n","# %% PLOTTING PREDICTION ON TRAINING DATA\n","################################################################################\n","\n","fig = mp.figure(figsize=(8,8))\n","\n","X_pred = X_test[id]\n","X_pred = X_pred[np.newaxis]\n","y_pred = model.predict(X_pred)\n","\n","mp.imshow(X_pred[0])\n","mp.imshow(y_pred[0, :, :, 0], alpha=0.5)\n","mp.axis('off')\n","mp.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CF1GaBaAn4y4","colab_type":"code","colab":{}},"source":["################################################################################\n","# %% SAVE HISTORY TO CSV FOR FURTHER PROCESSING\n","################################################################################\n","\n","hist = pd.DataFrame()\n","hist['loss'] = np.array(loss).flatten()\n","hist['val_loss'] = np.array(val_loss).flatten()\n","hist['acc'] = np.array(acc).flatten()\n","hist['val_acc'] = np.array(val_acc).flatten()\n","\n","hist.to_csv('drive/My Drive/Data/hist1.csv')"],"execution_count":0,"outputs":[]}]}